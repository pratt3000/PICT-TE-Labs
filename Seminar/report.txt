\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }
\usepackage[a4paper,left=1.5in,right=1in,top=1in,bottom=1in]{geometry}

\usepackage{tikz}
\usetikzlibrary{positioning,shapes,fit,arrows}
\definecolor{myblue}{RGB}{56,94,141}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{etoolbox}
%\apptocmd{\thebibliography}{\csname phantomsection \endcsname \addtocontentsline{toc}{chapter}{\bibname}}{}{}
\usepackage{caption}
\usepackage{float}
\floatstyle{boxed} 
\restylefloat{figure}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\footnotesize \center SELF SUPERVISED LEARNING IN IMAGES }
\fancyfoot[CE,CO]{ \raggedright{P:F-SMR-UG/08/R0} }
\fancyfoot[LE,RO]{\thepage}

\begin{document}
 
\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \large
                \textbf{Pune Institute of Computer Technology}	
                \linebreak
		\textbf{Dhankawadi, Pune}
        \vspace{0.5cm}
                        \linebreak
                        \linebreak
        \textbf{A SEMINAR REPORT }
        \linebreak
        \textbf{ON }
        \linebreak
        \vspace{0.5cm}
        \large
        \\SELF SUPERVISED LEARNING IN IMAGES 
        \linebreak
        \linebreak
		
		%\vspace{0.2cm}
		\textbf{SUBMITTED BY}
		\vspace{1cm}
		
        \textbf{ Prathamesh Sonawane }
        \\ Roll No. 31164   
        \\ Class TE 1
        \linebreak
        \linebreak
		        
        \textbf{\large{Under the guidance of}}
		\linebreak
	    Prof. Rujuta Kulkarni
		\linebreak
      %  \vfill
        
        
        
        \vspace{0.8cm}
        

        \includegraphics[scale=0.6]{pict}   
        
        \Large
        DEPARTMENT OF COMPUTER ENGINEERING\\
%        \textbf{Pune Institute of Computer Technology}	
%		\textbf{Dhankawadi, Pune}
%		\linebreak
		\textbf{Academic Year 2021-22}
        
    \end{center}
\end{titlepage}
\pagebreak
%2
\begin{titlepage}
\begin{center}
	\includegraphics[scale=0.6]{pict} 
	\linebreak
	\Large
        DEPARTMENT OF COMPUTER ENGINEERING\\
        \textbf{Pune Institute of Computer Technology}
		\linebreak
		\textbf{Dhankawadi, Pune-43}
		\vspace{0.8cm}
		\Large
		
	    \textbf{CERTIFICATE}
	    		\linebreak
	    \linebreak
		This is to certify that the Seminar report entitled
        \linebreak
		\linebreak
		\large
		\textbf{“SELF SUPERVISED LEARNING IN IMAGES”}
		\linebreak
		\linebreak
		Submitted by
		\linebreak
		Prathamesh Sonawane \hspace{10mm}   Roll No. 31164 \linebreak
		\linebreak
		has satisfactorily completed a seminar report under the guidance of Prof. Rujuta Kulkarni towards the partial fulfillment of third year Computer Engineering Semester II, Academic Year 2019-20 of Savitribai Phule Pune University. 
		\linebreak
		\linebreak
		\linebreak
		\linebreak
		\linebreak
		\begin{table}[h]
		\begin{tabular}{ccc}
		Dr. A. R. Deshpande    &                        &  \hspace{52mm} Prof. M.S.Takalikar\\
		Internal Guide      &                     &    \hspace{52mm} Head \\
		          &                         &       \hspace{47mm} Department of Computer Engineering \\
                    &                       & \hspace{52mm} 
		\end{tabular}
		\end{table}
		\end{center}
Place: Pune\\
Date: 29/05/21

\end{titlepage} 

\pagenumbering{Roman}
\section*{ACKNOWLEDGEMENT}

\hspace{0.5cm} I sincerely thank our Seminar Coordinator Prof. B.D.Zope and Head of Department Prof. M.S.Takalikar
for their support.
\vspace{0.25cm}
\par I also sincerely convey my gratitude to my guide Prof. Rujuta Kulkarni, Department of Computer Engineering for her constant
support, providing all the help, motivation and encouragement from beginning till end to make this seminar a grand success.
\vspace{0.25cm}
\par

\newpage
\tableofcontents

\newpage
\listoftables
\listoffigures

\newpage

\section*{Abstract}
Many recent methods self-supervised representation learning train feature extractors by maximizing an estimate of the mutual information (MI) between different views of the data. In this literature survey we discuss and provide evidence to analyze the extent to which maximizing Mutual Information (MI) between vectors has an effect on training feature extractors.2 images are passed through particular feature extractors and  2 independent 2D-vectors for each of the images respectively are created. Following this MI is calculated using a predefined formula between these 2 vectors, using one among a variety of estimators (InfoNCE, InfoMAX, etc). The primary task is to maximize this MI. After noting down initial results they discuss if employing a better MI formula is the only way in which we could get better feature extractors. This paper is to prove that maximization of mutual information, and focusing on improving solely that is not a necessary and/or sufficient condition for beating current SOTA results. It also suggests that while all of this is true we must continue to pursue better formulae to find MI as although it isn’t solely responsible for the performance of our experiment but it does play a vital role in it.
\par 
Another new approach to self-supervised image
representation learning is BYOL (Bootstrap your own latent), it relies on two neural networks, referred to as online and target
networks, that interact and learn from each other.

\par

\section*{Keywords}
Self-supervised learning, Unsupervised representation, Mutual Information, InfoMAX, InfoNCE, pre-trained models.
\newpage
\pagenumbering{arabic}
\begin{center}
\section{INTRODUCTION}
\end{center}
\par
Self supervised learning these days has become essential, considering the amount of data that is needed to train models it is highly effective to create labels empirically rather than by manual effort. Since the in many cases the amount of data may determine the output quality of our predictors, investing millions into creating sub par labelled data sets isn't feasible anymore. The amount of unlabelled data out numbers labelled data 1:1 million, and considering there is no way to label all of the data self supervised learning comes in handy.
 \\ 
\par
Learning good image representations is a key challenge
in computer vision as it allows for efficient
training on downstream tasks. Many different training approaches have been proposed to learn
such representations, usually relying on visual pretext
tasks.\\

\par
Self supervised learning is a relatively new area of research and requires more than average amount of compute while experimenting because of the sheer scale of things. Training times can vary from 2 days to 2 months and this makes it quite inapproachable` to lay persons. But with the resent onset of online cloud computing it has become somewhat accessible and as we get better hardware the training times are being reduced to. The reason they require such high compute is because the weights are always randomly initialized and due to the absence of transfer learning the model takes longer to converge to a minimum.\\

\\

\par 
BYOL introduces a novel method for self supervised learning in image representations. It achieve a higher score than any other state-of-the-art contrastive method.In this there are 2 networks online and target, these two networks work together and help each other learn. Two augmented images are created and passed into each of the networks the aim of this exercise is to get the same vector representation for different versions of an image, in the hope that the network will learning key features along the way of achieving this.\\

\\

\par
Similarly there are various other techniques used over the years. Jigsaw++ divides the images into parts like a jigsaw puzzle and the aim is for the network to predict the relative positions of the patches of the image. Another one is ROTNET in which the net tries to predict the angle to which the image is rotated. Colorful image colorization aims to convert black and white images to colored one using U-net architectures. As we can concur Self supervised learning involves a lot of imagination and coming up with a novel technique which may help the feature extractors understand images in a better way is the crux of it
\\

\par


\newpage
\begin{center}

\section{MOTIVATION}

\end{center}
\hspace{1cm} 
Given a task and enough labels, supervised learning can solve it really well. Good performance usually requires a decent amount of labels, but collecting manual labels is expensive (i.e. ImageNet) and hard to be scaled up. Considering the amount of unlabelled data (e.g. free text, all the images on the Internet) is substantially more than a limited number of human curated labelled datasets, it is kinda wasteful not to use them. However, unsupervised learning is not easy and usually works much less efficiently than supervised learning.
\\

\hspace{1cm}
In recent times we invest a lot of time and capital in labelling individual images to build a network around them. A decade ago the solution would have been transfer learning but for transfer learning we need pre-trained weights, pre-trained weights need to be trained in the first place. Now we could say that they could be trained on another data set, bt that defeats the purpose since creating that data set did take time at some point. This is where self supervised learning came into place. The idea that we don't really need labelled data sets in order to build a good feature extractor is really fascinating.
\\

  

\hspace{1cm} 

This doesn't mean that self supervised learning doesn't need labels, many tasks do require labels, but those labels are created by the computer and thus it takes significantly less amount of effort to make those labels. Although all of this is extremely promising, for the time being researchers have been trying to find out the optimum pretext task which could compete with data sets where labels are made manually.
\\



\hspace{1cm}\\
Many ideas have been proposed for self-supervised representation learning on images. A common workflow is to train a model on one or multiple pretext tasks with unlabelled images and then use one intermediate feature layer of this model to feed a multinomial logistic regression classifier on ImageNet classification. The final classification accuracy quantifies how good the learned representation is.

\newpage
\begin{center}

\section{LITERATURE SURVEY}

\end{center}

The Following table shows the literature survey by comparing techniques propose in various references:

\begin{center}
\begin{flushleft}

\begin{table}[h!]
 \caption{Literature survey}
 \begin{tabular}{|l|l|c|l|l|l|}
\hline
 No.
 & Techniques 
 & Dataset  
 & Architecture  
 & parameters 
 & Accuracy  \\ 
 \hline
 
 1 &\begin{tabular}[c]{@{}l@{}}
        Bootstrap\\ Your Own\\ Latent A New\\ Approach to \\Self-Supervised\\ Learning  
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        imagenet\\
        cifar100 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        online and\\ target \\networks : \\Siamese \\style (Resnets)
    \end{tabular}
 &  \begin{tabular}[c]{@{}l@{}}
        250 million
    \end{tabular}     
 & \begin{tabular}[c]{@{}l@{}}
        74.3/ 79.6 \\(Imagenet)
    \end{tabular} \\ 
    \hline
    
 2 &\begin{tabular}[c]{@{}l@{}}
        On mutual\\ information \\maximization \\for \\representation\\ learning  
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        MNIST\\
        CIFAR10 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        Custom \\MLP arch.
    \end{tabular}
 &  \begin{tabular}[c]{@{}l@{}}
        250 million
    \end{tabular}     
 & \begin{tabular}[c]{@{}l@{}}
        85 (MNIST)
    \end{tabular} \\ 
    \hline
    
 3 &\begin{tabular}[c]{@{}l@{}}
    Self-labelling\\ via \\simultaneous\\ clustering \\and\\ representation\\ learning 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        SVHN\\
        CIFAR-10\\
        CIFAR-100\\
        ImageNet 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        Custom \\MLP arch.
    \end{tabular}
 &  \begin{tabular}[c]{@{}l@{}}
        230 million
    \end{tabular}     
 & \begin{tabular}[c]{@{}l@{}}
        77.2  (Imagenet)
    \end{tabular} \\ 
    \hline
    
4 &\begin{tabular}[c]{@{}l@{}}
    Unsupervised\\ Visual \\Representation\\ Learning \\by Context\\ Prediction 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        ImageNet 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        Custom arch.
    \end{tabular}
 &  \begin{tabular}[c]{@{}l@{}}
        200 million
    \end{tabular}     
 & \begin{tabular}[c]{@{}l@{}}
        54.2  (Imagenet)
    \end{tabular} \\ 
    \hline
    
5 &\begin{tabular}[c]{@{}l@{}}
    A critical\\ analysis of \\self-supervision, \\or what we\\ can learn from \\a single image
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        ImageNet 
    \end{tabular} 
 &  \begin{tabular}[c]{@{}l@{}}
        BIGGAN \\Rotnet \\ Deep Cluster\\ Alexnet \\monoGAN
    \end{tabular}
 &  \begin{tabular}[c]{@{}l@{}}
        150 million
    \end{tabular}     
 & \begin{tabular}[c]{@{}l@{}}
        72.3 (Imagenet)
    \end{tabular} \\ 
    \hline

 

 \end{tabular}

\end{table}                             


%\\
%\\


\end{flushleft}
\end{center}

\newpage
\begin{center}
\section{A SURVEY ON PAPERS}
\end{center}
\subsection{Bootstrap Your Own Latent A New Approach to Self-Supervised Learning}
\hspace{1cm}
BYOL method helps in learning useful representations for a variety of downstream computer vision tasks such as object recognition, object detection, semantic segmentation, etc. Once these representations are learned in BYOL way, they could be used with any standard object classification model such as Resnet, VGGnet, or any semantic segmentation network such as FCN8s, deeplabv3, etc or any other task-specific network and it gets to a better result than training these networks from scratch. This is the major reason behind the popularity of BYOL. The below graph shows that the BYOL representations learned using Imagenet images beats all previous unsupervised learning methods and achieves classification accuracy of 74.1 percent with Resnet50 under linear evaluation protocol.\\
\\
Another interesting fact is, although a collapsed solution exists for the task curated for BYOL, the model avoids it safely and the actual reason for it is unknown. Collapsed solution means, the model might get away by learning a constant vector for any view of any image and gets to zero loss, but it does not happen\\
\\
The authors of the original paper, conjecture that it might be due to the complex network(Deep Resnet with skip connections) used in the backbone, the model never gets to the straightforward collapsed solution. But in another recent paper SimSiam Chen, Xineli and He, found out it is not the complex network architecture but the “stop-gradient” operation that makes the model to avoid the collapsed representations. “stop-gradient” means that the network never gets to update the weights of the target network directly through gradients and hence never gets to the collapsed solution. They also show that there isn’t any need for a momentum target network to avoid collapsed representation but it certainly gives better representations for downstream tasks if used.


\subsection{CIDS: A framework for intrusion detection
in cloud systems}
\hspace{1cm}  
Each node has two IDSs detectors, CIDS and HIDS. In this way, the node can cooperatively participate in intrusion detection by identifying the local events that could represent security violations and by exchanging its audit data with other nodes.
the sharing of information among the following CIDS components:
\textbf{Cloud nodes}: contains the resources homogeneously accessed through the cloud middleware.
\textbf{Guest task}: it is a sequence of actions and commands submitted by a user to an instance of VM.
\textbf{Logs and audit collector}: it acts as a sensor for both CIDS and HIDS detectors and collects logs, audit data, and sequence of user actions and commands.
\textbf{VM}: it encapsulates the system to be monitored using VMM. The detection mechanisms are implemented outside the VM, i.e. out of reach of intruders. A single instance of a VM monitors can observe several VMs.


\subsection{Performance Metric Selection for Autonomic
Anomaly Detection on Cloud Computing Systems}
\hspace{1cm} 
To make the anomaly detection tractable and yield high
accuracy, the paper apply dimensionality reduction, which transforms
the collected health data to a new metric space with only
the more relevant attributes preserved. We apply two
approaches to reducing dimensionality: metric selection using
mutual information and metric extraction by principal component
analysis.\\


\subsection{A SVM Model based on Network Traffic Prediction for Detecting Anomalies}
\hspace{1cm} The purpose of our Anomaly Detection Mechanism is to provide an efficient
method to detect anomalies in the cloud-based network traffic. Figure
1 depicts the basis of our mechanism, by highlighting the application
scenario and the main conceptual components.\\
The cloud provider offers several services by the Internet, such as infrastructure,
software and platform to the clients. Real-time cloud traffic
data (Flow 1) is continuously being gathered from the cloud environment
by the Cloud Monitoring module. This information is subsequently processed
by the Poisson-based Predictor that performs prediction based on
information such as the protocol type, the number of network packets and
timestamp.\\
After that, the SVM Model is fed with features extracted from the
predicted data. Then, the SVM Model triggers a warning to the
Event Auditor when an anomalous behaviour is detected. In
the meantime, the Repository of Outcomes component stores a detailed
output regarding the historic of the Virtual Machine (VM) operation. Furthermore, the Event Auditor represents an agent placed in the VM
that is able to communicate collaboratively with agents in the other VMs.
This agent receives any anomalous event from the SVM Model and builds
a message with information of all components for sending alerts
to other agents.
Having presented an overview of the anomaly detection mechanism,
in the following subsections there will be a more detailed description of
the forecasting approach for estimating network traffic on the basis of
a Poisson process and the Support Vector Machine model for detecting
anomalies in the cloud-based environment.




\newpage
\begin{center}
\section{PROBLEM DEFINITION AND SCOPE}
\end{center}

\subsection{Problem Definition}

\hspace{1.5cm} To design a system to extract the meaningful features from large dataset to increase the efficiency of anomaly detection.

\subsection{Scope}

\hspace{1.5cm} The successful attacks causing damages have a high level of effect on the result. Hence to lower down this effect countermeasure play an important role which surpasses the damage done. These countermeasure are responsible for maintaining the effectiveness of results in machine learning \\

\hspace{1.5cm} For the above purpose selection of labels from data set is most important task, whole functioning depends on selection of labels. As if wrong features or labels get selected then it will have adverse effect on system performance.
\hspace{1.5cm} Result of anomaly detection will purely depend on how we select the labels to go ahead for other operations.
\newpage
\begin{center}
\section{DIFFERENT MACHINE LEARNING ALGORITHM}
\end{center}
\subsection{Support Vector Machine (SVM)}
\par
\hspace{1cm}
It is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. It has high prediction
accuracy and performance rate but is limited to two classified classes only.
%\\
%\\
\subsection{Decision Tree classifiers}
\par
\hspace{1cm}
It repetitively divides
the working area(plot)
into sub part
by identifying
lines.Operations are
carried with
optimization.Effciency reduces
with increase
in dataset.
\\
\\


\subsection{KNN}
\par 
%\hspace
A simple algorithm
that stores
all available
cases and classifies
new cases
based on
a similarity
measure (e.g.,
distance functions)
Based on optimal
solution
time complexity
is quite
high.
\newpage
\begin{center}
\section{METHODOLOGY}

\end{center}
\subsection{Workflow}
\includegraphics[width=\linewidth]{pict}
\captionof{figure}{This is placeholder image: Workflow}
\newpage
\subsection{Mathematical model}
\par
S = \{s, e, X, Y, $f_{main}$, $f_f$, DD, NDD, $mem_{sh}$ $\vert$  $\phi$ \}\\\\
 s: start state.\\
 e: end state.\\

Let X be the input set consisting of:-  X = $L_i$\\
where L is the collected Log from monitoring cloud \\
Let Y be the output set consisting of:-\\
Y = {C,P} where C $\in$ Cl is class defined as anomaly. \\\\

\par
\textbf{Functions}\\\\
$f_{main}$ - Let ’k’ be the function to detect the anomaly  such  that:-\\
\\
k : log dataset $\rightarrow$  {P}\\
\\
$f_{f}$ : { $f_{1}$, $f_{2}$ }\\
\\
$f_{1}$= Cloud Monitoring functions for collecting data\\
\\
$f_{2}$= Anomaly detection function\\
\\
\textbf{Success- Failure Rate}\\

$\#$ P = normal\\
$P = {\phi}$ \\or\\ \# P $\neq$ normal

			
		

\newpage
\section{Results}
\subsection{Data}
\begin{table}[h!]
\centering
\caption{Data Table}
\begin{tabular}{|l|l|l|}
\hline
S.No &Data set  &size  \\ \hline
1 &KDD1998  &43.5 MB  \\ \hline
 2& KDD 1999 &75.3 MB  \\ \hline
\end{tabular}
%\caption{Data Table}
\label{my-label}
\end{table}
\subsection{Implementation Results}
\includegraphics[scale=0.5]{pict}
\captionof{figure}{This is placeholder image: Result of KDD 1998 dataset}
\includegraphics[scale=0.5]{pict}
\captionof{figure}{This is placeholder image: Result of KDD 1999 dataset}
\newpage
\begin{center}
\section{CONCLUSION}
\end{center}
\par
Feature extraction process can affect the system in both ways if the process is not carried out carefully. As features in machine learning is among the important factors which affects the system performance. Feature extraction along with supervised learning algorithm can improve the performance of anomaly detection system to an extent. Reducing the dataset through feature extraction make easy for learning algorithm to focus on important feature and get the work done  
\\

\newpage
%
%\bibliography{biblio}
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}

\begin{thebibliography}{21}
\bibitem{paper1} Dalmazo, Bruno L., et al. "Expedite feature extraction for enhanced 	cloud anomaly detection." Network Operations and Management 	Symposium (NOMS), 2016 " \textit{IEEE/IFIP. IEEE, 2016}.

\bibitem{paper2} T. Shon and J. Moon, “A hybrid machine learning approach to 	network anomaly detection,” Information Sciences, vol. 177, no. 18, 	pp. 3799 – 3821, 2007. [Online]. Available.

\bibitem{paper3} H. Kholidy and F. Baiardi, “CIDS: A framework for intrusion 	detection in cloud systems,” in Ninth International Conference on 	InformationTechnology: New Generations (ITNG), 2012, April 2012, 	pp. 379–385.

\bibitem{paper4} Fu, Song. "Performance metric selection for autonomic anomaly 	detection on cloud computing systems." Global Telecommunications 	Conference (GLOBECOM 2011), 2011 IEEE. IEEE, 2011.

\bibitem{paper5} S.-J. Horng, M.-Y. Su, Y.-H. Chen, T.-W. Kao, R.-J. Chen, J.-L. Lai,	and C. D. Perkasa, “A novel intrusion detection system based on 	hierarchical clustering and support vector machines,” Expert Systems 	with Applications, vol. 38, no. 1, pp. 306 – 313, 2011.


\bibitem{paper6} P. Ganeshkumar and N. Pandeeswari, “Adaptive neuro-fuzzy-based 	anomaly detection system in cloud,” International Journal of Fuzzy 	Systems, pp. 1–12, 2015.


\bibitem{paper7}B. L. Dalmazo, J. P. Vilela, and M. Curado, “Online traffic prediction 	in the cloud: A dynamic window approach,” in The 2nd International 	Conference on Future Internet of Things and Cloud (FiCloud’2014), 	Aug 2014, pp. 9–14.



\end{thebibliography}

\newpage

attach your review and visit log here......

\newpage

attach  plagiarism report here.....

\end{document}

